{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, AutoConfig\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame-level classifications: [{'frame': 0, 'classifications': []}, {'frame': 30, 'classifications': ['caucasian']}, {'frame': 60, 'classifications': ['hispanic']}, {'frame': 90, 'classifications': []}, {'frame': 120, 'classifications': []}, {'frame': 150, 'classifications': ['caucasian']}, {'frame': 180, 'classifications': ['african', 'caucasian', 'caucasian', 'caucasian']}, {'frame': 210, 'classifications': ['african', 'caucasian', 'caucasian', 'african']}, {'frame': 240, 'classifications': ['caucasian', 'caucasian']}, {'frame': 270, 'classifications': ['caucasian']}, {'frame': 300, 'classifications': ['caucasian']}, {'frame': 330, 'classifications': ['caucasian']}, {'frame': 360, 'classifications': ['caucasian', 'caucasian', 'caucasian', 'caucasian']}, {'frame': 390, 'classifications': ['caucasian']}, {'frame': 420, 'classifications': ['caucasian']}, {'frame': 450, 'classifications': ['caucasian', 'caucasian']}, {'frame': 480, 'classifications': ['caucasian']}, {'frame': 510, 'classifications': ['caucasian', 'caucasian']}, {'frame': 540, 'classifications': ['caucasian']}, {'frame': 570, 'classifications': ['caucasian']}, {'frame': 600, 'classifications': ['caucasian', 'caucasian']}, {'frame': 630, 'classifications': ['african', 'caucasian', 'asian']}, {'frame': 660, 'classifications': ['caucasian', 'asian']}, {'frame': 690, 'classifications': ['caucasian', 'asian']}, {'frame': 720, 'classifications': ['caucasian']}, {'frame': 750, 'classifications': ['caucasian']}, {'frame': 780, 'classifications': ['caucasian', 'hispanic']}, {'frame': 810, 'classifications': ['caucasian', 'hispanic', 'caucasian']}, {'frame': 840, 'classifications': ['caucasian', 'hispanic', 'caucasian']}, {'frame': 870, 'classifications': ['caucasian', 'hispanic', 'caucasian']}, {'frame': 900, 'classifications': ['caucasian']}, {'frame': 930, 'classifications': ['caucasian']}, {'frame': 960, 'classifications': ['caucasian', 'hispanic']}, {'frame': 990, 'classifications': ['caucasian', 'hispanic', 'caucasian']}, {'frame': 1020, 'classifications': ['african', 'caucasian', 'caucasian', 'caucasian', 'caucasian']}, {'frame': 1050, 'classifications': ['african', 'caucasian', 'caucasian', 'caucasian']}, {'frame': 1080, 'classifications': ['indian', 'caucasian', 'caucasian', 'asian']}, {'frame': 1110, 'classifications': ['african', 'caucasian', 'caucasian', 'caucasian']}, {'frame': 1140, 'classifications': ['caucasian']}, {'frame': 1170, 'classifications': ['caucasian']}, {'frame': 1200, 'classifications': ['caucasian']}, {'frame': 1230, 'classifications': ['caucasian']}, {'frame': 1260, 'classifications': ['caucasian']}, {'frame': 1290, 'classifications': []}, {'frame': 1320, 'classifications': ['asian']}, {'frame': 1350, 'classifications': ['asian']}, {'frame': 1380, 'classifications': ['hispanic']}, {'frame': 1410, 'classifications': ['caucasian', 'caucasian']}, {'frame': 1440, 'classifications': ['caucasian', 'indian']}, {'frame': 1470, 'classifications': ['caucasian', 'caucasian']}, {'frame': 1500, 'classifications': ['caucasian', 'caucasian', 'caucasian']}, {'frame': 1530, 'classifications': ['caucasian', 'caucasian', 'caucasian', 'caucasian', 'asian']}, {'frame': 1560, 'classifications': ['caucasian']}, {'frame': 1590, 'classifications': ['caucasian', 'indian']}, {'frame': 1620, 'classifications': ['caucasian', 'caucasian']}, {'frame': 1650, 'classifications': ['caucasian', 'caucasian']}, {'frame': 1680, 'classifications': ['caucasian']}, {'frame': 1710, 'classifications': ['caucasian']}, {'frame': 1740, 'classifications': ['caucasian']}, {'frame': 1770, 'classifications': ['caucasian']}, {'frame': 1800, 'classifications': ['caucasian']}, {'frame': 1830, 'classifications': ['caucasian']}, {'frame': 1860, 'classifications': ['african', 'caucasian', 'caucasian']}, {'frame': 1890, 'classifications': ['caucasian']}, {'frame': 1920, 'classifications': ['caucasian']}, {'frame': 1950, 'classifications': ['caucasian']}, {'frame': 1980, 'classifications': ['caucasian']}, {'frame': 2010, 'classifications': ['caucasian']}, {'frame': 2040, 'classifications': ['caucasian', 'caucasian']}, {'frame': 2070, 'classifications': ['caucasian']}, {'frame': 2100, 'classifications': ['caucasian']}, {'frame': 2130, 'classifications': ['caucasian']}, {'frame': 2160, 'classifications': ['caucasian']}, {'frame': 2190, 'classifications': ['caucasian', 'african', 'caucasian']}, {'frame': 2220, 'classifications': ['african', 'caucasian', 'african']}, {'frame': 2250, 'classifications': ['caucasian']}, {'frame': 2280, 'classifications': ['caucasian', 'caucasian']}, {'frame': 2310, 'classifications': ['caucasian', 'caucasian']}, {'frame': 2340, 'classifications': ['indian']}, {'frame': 2370, 'classifications': ['caucasian']}, {'frame': 2400, 'classifications': ['indian']}, {'frame': 2430, 'classifications': ['caucasian', 'african', 'caucasian']}, {'frame': 2460, 'classifications': ['caucasian']}, {'frame': 2490, 'classifications': ['caucasian']}, {'frame': 2520, 'classifications': ['caucasian', 'indian', 'caucasian']}, {'frame': 2550, 'classifications': []}, {'frame': 2580, 'classifications': ['hispanic', 'caucasian']}, {'frame': 2610, 'classifications': []}, {'frame': 2640, 'classifications': ['caucasian']}, {'frame': 2670, 'classifications': ['caucasian', 'caucasian']}, {'frame': 2700, 'classifications': ['african']}, {'frame': 2730, 'classifications': []}, {'frame': 2760, 'classifications': ['caucasian', 'caucasian', 'african', 'caucasian', 'caucasian', 'african']}, {'frame': 2790, 'classifications': ['caucasian', 'caucasian', 'caucasian']}, {'frame': 2820, 'classifications': []}, {'frame': 2850, 'classifications': ['caucasian']}, {'frame': 2880, 'classifications': ['caucasian']}, {'frame': 2910, 'classifications': ['caucasian', 'caucasian']}, {'frame': 2940, 'classifications': ['caucasian', 'caucasian']}, {'frame': 2970, 'classifications': []}, {'frame': 3000, 'classifications': []}, {'frame': 3030, 'classifications': []}, {'frame': 3060, 'classifications': ['caucasian']}, {'frame': 3090, 'classifications': []}, {'frame': 3120, 'classifications': []}, {'frame': 3150, 'classifications': []}, {'frame': 3180, 'classifications': []}, {'frame': 3210, 'classifications': []}, {'frame': 3240, 'classifications': []}, {'frame': 3270, 'classifications': []}, {'frame': 3300, 'classifications': []}, {'frame': 3330, 'classifications': []}, {'frame': 3360, 'classifications': []}, {'frame': 3390, 'classifications': []}, {'frame': 3420, 'classifications': []}, {'frame': 3450, 'classifications': []}, {'frame': 3480, 'classifications': []}, {'frame': 3510, 'classifications': []}, {'frame': 3540, 'classifications': []}, {'frame': 3570, 'classifications': []}, {'frame': 3600, 'classifications': []}, {'frame': 3630, 'classifications': []}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"cledoux42/Ethnicity_Test_v003\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"cledoux42/Ethnicity_Test_v003\")\n",
    "config = AutoConfig.from_pretrained(\"cledoux42/Ethnicity_Test_v003\")\n",
    "id2label = config.id2label\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "video_path = '/Users/qwu_sf/CelebV-HQ/downloaded_celebvhq/raw/vtznSlhouZc.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_rate = 30  # standard frame rate: 30 frames per second \n",
    "frame_count = 0\n",
    "results = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_count % frame_rate == 0:\n",
    "        frame_results = []  # Store classifications for this frame\n",
    "\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Crop the face region\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            pil_face = Image.fromarray(face_rgb)\n",
    "\n",
    "            inputs = processor(images=pil_face, return_tensors=\"pt\")\n",
    "\n",
    "            # Classification\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                predicted_class = predictions.argmax().item()\n",
    "                predicted_label = id2label[predicted_class]\n",
    "\n",
    "            frame_results.append(predicted_label)\n",
    "\n",
    "        results.append({\"frame\": frame_count, \"classifications\": frame_results})\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "print(\"Frame-level classifications:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
